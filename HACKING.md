<!-- Copyright Shroud Project Developers. See LICENSE file for details. -->
<!-- SPDX-License-Identifier: (BSD-3-Clause)                            -->

This file describes the development process for Shroud.
This includes setting up a development environment, running tests
and creating a release.

# Directory structure

After cloning the repository, the directories will be as follows.
Except for the `build` directory which is created by the Makefile.

    build           # created by Makefile
       sphix        # Generated documentation
       $tempdir
         regression # Output of regression tests
         run        # Output from compiled tests
         venv       # Virtual environment
    compiler
       # Directories of code to test compiler features
    docs            # RST files for documentation.
    shroud          # Python source
    regression
      input
         prob.yaml
      reference
         prob
            # Files generated by Shroud
      run
         prob
            # The library wrapped for the problem.
    tests
       # unittest python code

# Development

All development is driven by the top level `Makefile`.

## Create development environment

A virtual environment is created and the YAML package is installed.
Defaults to Python 3.

    make virtualenv
    make develop

`make develop` allows changes to be seen without installed the module again.

The *tempdir* can be verified with `make print-tempdir`.
Similar to `temp.linux-x86_64-3.9`.

For python2, soon to be dropped, edit the top level Makefile to
comment out the line `PYTHONEXE := python3`. It will then use the
python2 on your path.

    make virtualenv2
    make develop-setup

Note that due to dictionaries not being ordered in Python 2.7, the
*do-test* tests will produce different output in the JSON files.

# Documentation

Sphinx is used the create the documentation.
The files are in `docs` directory.

    make docs

Creates `build/sphinx/html/index.html`

    make pdf

Creates `build/sphinx/latex/shroud.pdf`

# Testing

## Run unittest

    make test

The unittests are in the `tests` directory.

Run a single unittest:

    cd tests
    ../build/$tempdir/venv/bin/python test_declast.py CheckParse.test_inheritance

Running a single Python unit test.

    # Use the Python in the virtual environment
    setenv WORK  .../build/$tempdir
    setenv PYTHONEXE $WORK/venv/bin/python

    cd tests
    $PYTHONEXE -m unittest test_ast.CheckAst.test_d_generate1

    # Run a regression test
    setenv PYTHONPATH $WORK/run/struct-class-c/python
    cd regression/run/struct-class-c/python
    $PYTHONEXE -m unittest test.Struct.test_Arrays1


## Parse test

Parse some strings in `tests/check_decl.py` and compare to reference
in `tests/check-decl.output`.
The parse trees are compared.

    make test-decl
    make test-decl-diff
    make test-decl-replace

## Regression tests

    make do-test

Run the script `regression/do-test.py` over some `regression/input` yaml files.

The output is saved in `build/$tempdir/regression`

A script is added to the output directory to help compare regression files.

   cd $WORK/build/$tempdir/regression/classes
   ./cmp-shroud

Update fiducials

    make do-test-replace [ do-test-args=tutorial ]

Running a single test

    make do-test do-test-args=tutorial


Running a test manually after adding lines like "import pdb;pdb.set_trace()".
First, run the test via do-test.  Extract run line from `test.log`.
It will contain paths and flags used to run `do-test`.

    cd $WORK/build/$tempdir/regression/classes
    $WORK/build/$tempdir/venv/bin/shroud ...  $WORK/regression/input/classes.yaml

## Test generated code

Compile the files in `regression/reference`.
The Library code which is wrapped is in the `regression/run` directory.

    make test-clean
    make test-all -k

Compile the generated code (after `do-test-replace`) and run some unit
tests.  These tests are in `regression/run` and contains a small library
which is wrapped by the corresponding yaml file
(i.e. `regression/input/tutorial.yaml` wraps `regression/run/tutorial`)
The `make -k` flag will keep-going if one of the tests fails.

`regression/run/Makfile` is `included` by the top level makefile.
`regression/run/default.mk` has compiler flags.

The default is to use `gcc`. Other compilers can be specified as:

    make compiler=oneapi test-all
    make compiler=intel test-all
    make compiler=cray test-all

Targets to compile a single test:

    fortran-XXX        compile wrappers for XXX.yaml
    test-fortran-XXX   run test for XXX.yaml
    test-fortran       All Fortran tests
    test-cfi           Fortran tests with C-Fortran-Interface

    test-c-XXX

    py-XXX             compile module for XXX.yaml
    test-python-XXX    run Python test for XXX.yaml
    test-python        All Python tests

The Fortran tests use `fruit`, C tests `assert`, and Python tests use `unittest`.

## test-commit

Runs `test-clean`, `test`, `test-decl`, and `do-test`. To be used before a commit.

    make test-commit

## Adding a regression test

* Add a file `regression/input/newtest.yaml`.
* Create directory `mkdir regression/reference/newtest`.
* Run the test `make do-test do-test-args=newtest`
* Look for errors in `$(tempdir)/regression/log.test`
* Add a call to TestDesc in `regression/do-test.py` to run *newtest*.
* `mkdir regression/run/newtest`
* Create files `Makefile`, `newtest.cpp` and `newtest.hpp`

* Add to variable *fortran-test-list-std* in
  `regression/run/Makefile` to run as part of `test-all` target.
  Try `make -n test-fortran-newtest` to see commands which will be
  run.


Several tests are run with language=c and c++.  To accomplish this,
the run/pkg files have the `.c` suffix. The `sync-cxx` target copies the
files to another directory with a `.cpp` suffix. This directory is added
to the `VPATH`.  For the Python tests, there is an explicit run to force
the use of CXX.  The VPATH finds both the C and C++ files since they
have the same stem.

Sample Fortran Makefile to allow `TEST_FFLAGS` to be in every compile
for a specific test.

```
testdir = xxx
TEST_FFLAGS = -DTEST_C_WRAPPER

C_OBJS = \
    xxx.o \
    wrapxxx.o
F_OBJS = \
    main.o \
    fruit.o \
    wrapfxxx.o

include $(top)/regression/run/defaults.mk

## dependencies

```

Sample Python makefile

```
testdir = xxx
pymodule = xxx.so

AS_SHARED := TRUE
include $(top)/regression/run/defaults.mk

PY_OBJS = \
    xxx.o
    pyxxxmodule.o

# dependencies

```

# Debugging

## Wrappers

There are a couple of Shroud YAML options that provide useful
debugging information.

    options:
      debug: True
      debug_index: True

The **debug** option writes additional information into the generated
files.  This includes which statement group was used for each
argument. This makes it easier to understand how the wrapper is being
generated.

The **debug_index** requires the **debug* option to also be True.  It
dump out more information such as the `_function_index` and
`signature` fields.  `_function_index` is an integer index used to
uniquely identify each funtion to map between the generated code and
the internal state dump into the JSON output file.  `signature` is a
collection of statement group indexes Shroud uses to help identify if
two possible wrappers are the same.

**debug** is used in the testsuite to help identify when something
changes.  Using **debug_index** will produce excessive change when a
function is added to a test or a statement group is added to
`fc-statement.json`.  The additions can cause indexes to change
resulting in excessive changes.  **debug_index** is designed for
debugging by the developer, not the user.

## memory debugging

Valgrind can be used by setting `valgrind=valgrind` on the Make command line.
Actually, `valgrind=path-to-valgrind`.

    make -k valgrind=valgrind test-all

Recompile code with address sanitizer.

    make test-clean ; make -k use_asan=1 test-all


## reference counting

`Python-3.9.12/Misc/valgrind-python.supp`

```
valgrind --tool=memcheck --suppressions=valgrind-python.supp \
                                          python -E -tt ./my_python_script.py
```

Build Python with `--with-address-sanitizer --with-pydebug`

# Development

## file dependency

```
main.py
wrapX.py  generate.py
fcfmt.py  metaattrs.py
ast.py
declast.py declstr.py fcmem.py
typemap.py statements.py todict.py
whelpers.py
util.py visitor.py
error.py  # no dependencies
metadata.py
```

```
Error with template: 'call SHROUD_copy_array_{cxx_T}({c_var_context}, {f_var}, size({f_var},kind=C_SIZE_T))'
```
can be debugged by changing util.wformat to remove comment to provide a backtrace.


## adding a type

typemap.py

ast.py LibraryNode.create_std_names()
  add to namespace

declast.py  get_canonical_typemap()
  Convert 'long int' into 'long'


## formatting generated code

Always use `{nullptr}` instead of `NULL`.  Helps C++.

## error checking

Write a `#error` line instead of generating bad code so the
compiler will point out the error.

## debugging

```
import yaml
print(yaml.dump(cf_tree, default_flow_style=False))

import pprint
pp = pprint.PrettyPrinter(indent=4)
pp.pprint( dict or tuple )
```

```
import pdb; pdb.set_trace()
```

```
% yes c | python ... >&! out
Answer 'c' to all pdb prompts.
```

To start pdb on an exception, uncomment line in main.py
```
#sys.excepthook = info
```

## pythondevmode

If this environment variable is set to a non-empty string, enable
Python Development Mode, introducing additional runtime checks that
are too expensive to be enabled by default.  New in version 3.7.

    setenv PYTHONDEVMODE 1

# Release

Update `docs/releases.rst` with changes and version number.
It is best to continually update this file as changes are made.

## Branch

Create a release branch.

## Version

Update version number in files

* `shroud/metadata.py`
* `setup.py`  Download path
* `pyproject.toml`
* `README.md`
* `pyproject.toml`
* `docs/conf.py`
* `docs/releases.rst`
* Update reference files with new version. `make do-test-replace do-test-args=none`

## Shiv

`shiv` is a command line utility for building fully self-contained
Python zipapps as outlined in PEP 441, but with all their dependencies
included!
shiv's primary goal is making distributing Python applications fast & easy.

https://pypi.org/project/shiv/

    make install-shiv
    rm dist-shiv/*
    make shiv-file
    make do-test-shiv

Move the shiv file to local system.

## PyPi

https://pypi.org/project/llnl-shroud/

> You need an account on pypi.org

## Spack

After a commit hash is created, update
`scripts/spack/packages/py-shroud/package.py`.

# Annual

Update copyright in `LICENSE`.

